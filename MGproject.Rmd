---
title: "MGpeach"
author: "Marissa Gay"
date: '2024-03-04'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
full <- read_csv("diagnosing_AD_data.csv")
library(dplyr) #needed for the %>% function in the data subset loops
library(ggplot2)
library(knitr)

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(readr)
library(dplyr)
library(tidyverse)
full <- read_csv("diagnosing_AD_data.csv")

head(full)

full %>% group_by(class) %>%
  summarise(mean(air_time1),
            mean(air_time2),
            mean(air_time3),
            mean(air_time4),
            mean(air_time5),
            mean(air_time6),
            mean(air_time7),
            mean(air_time8),
            mean(air_time9),
            mean(air_time10),
            mean(air_time11),
            mean(air_time12),
            mean(air_time13),
            mean(air_time14),
            mean(air_time15),
            mean(air_time16),
            mean(air_time17),
            mean(air_time18),
            mean(air_time19),
            mean(air_time20),
            mean(air_time21),
            mean(air_time22),
            mean(air_time23),
            mean(air_time24),
            mean(air_time25))

AD_airtime <- ggplot() + 
  geom_point(aes(x = ))

```

## Including Plots

You can also embed plots, for example:

```{r accessible subset}

a=1
b=6
c=15
access <- data.frame(matrix(nrow=174))

for (i in 1:25) {
  access <- access %>%
    mutate(full[a:(a+2)], full[b:(b+1)], full[c:(c+1)])
  
  a <- a+18
  b <- b+18
  c <- c+18
  
}

access <- access %>%
  mutate(full[451:452])

access <- subset(access, select = -(matrix.nrow...174.))



```

```{r tasks subset}
d <- 2

#for task 25 

for (i in (1:25)) {
  df25 <- data.frame(access[1], access[d:(d+6)])
  df25 <- df25 %>%
    mutate(access[177])
  
  assign( paste("Task", i, sep = "_"), df)
  d <- d+7
}

head(df25)


```
```{r}

#task23subset

d <- 2


for (i in (1:23)) {
  df23 <- data.frame(access[1], access[d:(d+6)])
  df23 <- df23 %>%
    mutate(access[177])
  
  assign( paste("Task", i, sep = "_"), df)
  d <- d+7
}

head(df23)



```

```{r}

#task14subset

d <- 2


for (i in (1:14)) {
  df14 <- data.frame(access[1], access[d:(d+6)])
  df14 <- df14 %>%
    mutate(access[177])
  
  assign( paste("Task", i, sep = "_"), df)
  d <- d+7
}


head(df14)

mean_data <- aggregate(max_x_extension14 ~ class, data = df14, FUN = mean)

ggplot() + theme_bw()+
  geom_histogram(aes(x = max_x_extension14, fill = class),
                          data = df14, 
                          bins = 100,
                          alpha = 0.5)+
  facet_wrap(~class)+
  scale_fill_discrete(name="Health Condition",
                         breaks=c("H", "P"),
                         labels=c("Healthy", "Alzheimer's Patient"))+
   geom_vline(data = mean_data, aes(xintercept = max_x_extension14, color = class),
             linetype = "dashed", size = 1, show.legend = FALSE)+
  labs(x= "Maximum X Extension", y = "Count")+
  ggtitle("Task 14 Maximum X Extension Distribution" )
  

```

```{r}
#task14subset

d <- 2


for (i in (1:10)) {
  df10 <- data.frame(access[1], access[d:(d+6)])
  df10 <- df10 %>%
    mutate(access[177])
  
  assign( paste("Task", i, sep = "_"), df)
  d <- d+7
}

head(df10)

ggplot() + theme_bw()+
  geom_histogram(aes(x = air_time10, fill = class),
                          data = df10, 
                          bins = 100)+
  facet_wrap(~class)+ 
  xlim(0,50000)+
  labs(x= "Air time (seconds)",
       y = "Count",
       fill = "Health Condition")+
   scale_fill_discrete(name="Health Condition",
                         breaks=c("H", "P"),
                         labels=c("Healthy", "Alzheimer's Patient"))+
  ggtitle("Task 10 Air time Distribution")
  



```

```{r}

d <- 2


for (i in (1:5)) {
  df5 <- data.frame(access[1], access[d:(d+6)])
  df5 <- df5 %>%
    mutate(access[177])
  
  assign( paste("Task", i, sep = "_"), df)
  d <- d+7
}

head(df5)

ggplot() + theme_bw()+
  geom_histogram(aes(x = disp_index5, fill = class),
                          data = df5, 
                          bins = 100)+
  facet_wrap(~class)+
  labs(x= "Dispersion Index",
       y = "Count",
       fill = "Health Condition")+
   scale_fill_discrete(name="Health Condition",
                         breaks=c("H", "P"),
                         labels=c("Healthy", "Alzheimer's Patient"))+
  ggtitle("Task 5 Dispersion Index Distribution")


```

##### Notes for steps to take #####

- recreate their data
    - divide dataset into training and test
    - exp1. uses entire dataset to train classifiers, no dividing by task
    - exp2. tests all classifiers. divides each time a single task on which each classifier is trained.
    - exp3. tests all classifiers again but only one run performed
    - exp4. combines outputs of classifier outputs through majority vote strategy
    - exp5. similar to exp1. uses features from a subset set of tasks, subset chosen by classification used.
    
- do it with our own dataset
  - basically do exp1 for just RF ???
  
THEIR random forest code translated to R via chatgpt

library(caret)

# Define the parameter grid

param_grid <- expand.grid(
  .n_estimators = c(100, 150, 200, 250, 300),
  .max_depth = c(3, 4, 5, 6, 7, 8, 9),
  .bootstrap = c(TRUE, FALSE)
)

# Define the training control for cross-validation

train_control <- trainControl(method = "cv", number = cross_val)

# Define the random forest model

model <- train(
  x = x_train,
  y = y_train,
  method = "rf",
  trControl = train_control,
  tuneGrid = param_grid,
  metric = "Accuracy"
  
)

```{r}

install.packages("randomForest")
#install.packages("superml")
#library(superml)
library(randomForest)
library(ggplot2)
set.seed(147)
head(access)

class(access)

access$class = as.character(access$class)
access$class = factor(access$class)

rfmodel <- randomForest(class ~ ., data = access, ntree= 51, importance = TRUE)

summary(rfmodel)

```

```{r}
#divide dataset

library(lattice)
library(caret)

sampsize <- floor(0.8*nrow(access))

sampsize

set.seed(49)
train_set <- sample(seq_len(nrow(access)), size = sampsize)

train <- access[train_set, ]
test <- access[-train_set, ]



#trainControl(
 # method = "oob",
 # repeats = 5, 
 # search = "grid(define this)" ,
 # savePredictions = "final", 
#)

train(x = access,
      ... = rfmodel,
                        ))


#train_control <- trainControl(method = "cv", number = cross_val)


```



```{r}

# result <- data.frame(test$class, predict(rf.testing, type = "response"))


param_grid <- list(
  list(clf__n_estimators = c(100, 150, 200, 250, 300),
       clf__max_depth = c(3, 4, 5, 6, 7, 8, 9)),
  list(clf__bootstrap = FALSE,
       clf__n_estimators = c(100, 150, 200, 250, 300),
       clf__max_depth = c(3, 4, 5, 6, 7, 8, 9))
)



# Define model

model <- rfmodel

library(superml)

scoring = 'accuracy' 
cross_val = 5
  
  
GridSearchCV(trainer = model,
                            parameters = param_grid,
                            n_folds = 5,
              scoring = accuracy)





```

#to see decision tree nodes
dot_data = sklearn.tree.export_graphviz(model, out_file=None,
                                       feature_names = train_X.columns,
                                       filled = True)
 
graph = graphviz.Source(dot_data)
 
# saving tree to png file
png_bytes = graph.pipe(format='png')
with open('decision_tree.png','wb') as f:
    f.write(png_bytes)


# tuning process

best_model <- model$finalModel

# Make predictions on the test set

predictions <- predict(best_model, newdata = x_test)

  # Make predictions on the test set
  
  predictions <- predict(best_model, newdata = x_test[, feature_cols])
  predictions_TS <- predict(best_model, newdata = x_train[, feature_cols])



  


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
